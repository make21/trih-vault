# The Rest Is History Pipeline — Product Requirements

## 1. Goal
Deliver a deterministic, append-only data pipeline that ingests *The Rest Is History* podcast RSS feed, layers in programmatic cleanup and cached LLM enrichments, and publishes stable JSON artefacts for downstream consumers. The new system must minimise LLM token usage, support incremental updates, and remove the legacy "topics" concept entirely.

## 2. Scope
- **In scope**
  - RSS ingestion from `https://feeds.megaphone.fm/GLT4787413333`.
  - Programmatic transforms that normalise episode text, strip boilerplate, and extract structured credits.
  - Deterministic series grouping with derived aggregates (e.g. `yearFrom`, `yearTo`).
  - LLM passes for episodes and series that consume the programmatic fingerprints and reuse cached responses.
  - Composition of public JSON outputs without regenerating historical data unnecessarily.
  - Schema-backed validation, referential integrity checks, and CI ergonomics.
- **Out of scope**
  - Any topic generation, storage, or validation.
  - UI or playback features; this PRD focuses purely on the data pipeline.

## 3. Personas & Needs
| Persona | Need |
| --- | --- |
| Data pipeline maintainer | Run a predictable, idempotent set of scripts locally or in CI without re-enriching unchanged items. |
| Downstream consumer | Read `public/episodes.json` and `public/series.json` with complete metadata, including deterministic episode cleanup and series spans. |
| Cost controller | Keep OpenAI usage low by caching outputs and avoiding re-requests unless fingerprints change. |

## 4. Data Model & Storage
### 4.1 Conventions & Identifiers
- **Canonical IDs**
  - `episodeId` = normalised RSS `<guid>` string. Persist the raw RSS GUID under `source.guid` for traceability.
  - `seriesId` = `slug(seriesKey) + "-" + firstPubYYYYMMDD` for the arc. This ID MUST be stable across reruns and cannot be reused for a different arc.
- **Source mapping** — Every episode retains `source` metadata:
  - `source.guid` (string, required)
  - `source.itunesEpisode` (number \| null, required, mirror the RSS value; null when absent)
  - `source.megaphoneId` (string \| null, optional; populate when present in the feed)
  - `source.enclosureUrl` (string, required)
- **Date handling**
  - `publishedAt` is an ISO 8601 UTC timestamp derived from RSS `pubDate`; present in all layers.
  - `rssLastSeenAt` is an ISO 8601 UTC timestamp representing the last time the RSS entry was observed; stored on raw episodes and propagated through programmatic and public layers.
  - Daily RSS snapshots (`data/source/rss.YYYY-MM-DD.json`) store `fetchedAt` (ISO 8601 UTC) at the file root for provenance.
- **Year semantics**
  - `yearFrom` and `yearTo` are `number \| null` throughout the pipeline.
  - Replace all prior `"NA"` sentinels with `null`.
  - `yearConfidence` captures precision with enum `"high" | "medium" | "low" | "unknown"`.
- **Series grouping confidence**
  - `seriesGroupingConfidence` enum `"high" | "medium" | "low"` documents how certain the programmatic grouping is.
  - Persist `seriesKeyRaw` when ambiguity remains; confidence defaults to `"low"` in that case.
- **Ordering & determinism**
  - `public/episodes.json` and `public/series.json` are arrays sorted by `publishedAt` ascending, then `episodeId`.
  - All JSON serialisation uses stable key ordering (sorted keys) to minimise diffs.

### 4.2 File Specifications
Explicit field inventories for each artefact:

#### `data/source/rss.YYYY-MM-DD.json`
- Root object with keys:
  - `fetchedAt` — string (ISO 8601 UTC), required.
  - `items` — array of raw RSS item payloads (structure defined by the feed), required; stored for auditing only.

#### `data/episodes-raw.json`
- Append-only array of episode metadata harvested from RSS.
- Fields per entry:

| Field | Type | Required | Notes |
| --- | --- | --- | --- |
| `episodeId` | string | Required | Normalised RSS GUID; canonical ID. |
| `title` | string | Required | Original episode title. |
| `publishedAt` | string | Required | ISO 8601 UTC derived from RSS `pubDate`. |
| `description` | string | Required | Raw HTML or text description from RSS. |
| `audioUrl` | string | Required | Direct media URL. |
| `rssLastSeenAt` | string | Required | ISO 8601 UTC when the item was last seen in RSS. |
| `source` | object | Required | Provenance object (`guid`, `itunesEpisode`, `megaphoneId`, `enclosureUrl`); `itunesEpisode` stored as number \| null. |

#### `data/episodes-programmatic.json`
- Deterministic enrichment stored as an object keyed by `episodeId`.
- Field expectations:
  - `cleanTitle` (plain text version of the episode title after cleanup).
  - `cleanDescriptionMarkdown` (Generated by parsing the source HTML. It must replace `<p>` tags with double newlines (`\n\n`) and `<br>` tags with single newlines (`\n`) to preserve paragraph structure for UI rendering).
  - `cleanDescriptionText` (Derived from `cleanDescriptionMarkdown` by stripping all remaining formatting and collapsing multiple whitespace characters into single spaces. The result must be a clean block of plain text suitable for LLM analysis).
  - *Rationale for two description fields:* This provides maximum flexibility. Downstream web UIs can easily render `cleanDescriptionMarkdown` as HTML with correct paragraph breaks. The `cleanDescriptionText` field provides a simplified, pure-text version optimized for LLM prompts and other machine-reading contexts without the noise of formatting characters.
- Fields per entry:

| Field | Type | Required | Notes |
| --- | --- | --- | --- |
| `episodeId` | string | Required | Mirrors raw `episodeId`. |
| `publishedAt` | string | Required | Carried through from raw layer. |
| `rssLastSeenAt` | string | Required | Copied from raw layer for provenance. |
| `cleanTitle` | string | Required | Plain text version of the episode title after cleanup. |
| `cleanDescriptionMarkdown` | string | Required | Markdown-like synopsis preserving paragraph breaks (double newlines for `<p>`, single newline for `<br>`). |
| `cleanDescriptionText` | string | Required | Formatting-free synopsis derived from `cleanDescriptionMarkdown` with collapsed whitespace. |
| `descriptionBlocks` | string[] | Required | Paragraph-level breakdown used by prompts. |
| `credits` | object | Optional | Keys map to contributor arrays (strings). |
| `fingerprint` | string | Required | See §5 for the algorithm; must reflect the `cleanupVersion`. |
| `cleanupVersion` | number | Required | Current deterministic cleanup version (initially `1`). |
| `derived` | object | Optional | Deterministic facts such as `durationSeconds` (number), `contentWarnings` (string[]), and `yearHints` (object with inferred numeric spans). |
| `part` | number \| null | Optional | Numeric part index; `null` when not applicable. |
| `seriesId` | string \| null | Optional | Stable identifier shared by multi-part arcs; required when `part` is non-null. |
| `seriesKey` | string \| null | Optional | Canonical human-readable key extracted from the title. |
| `seriesKeyRaw` | string \| null | Optional | Original ambiguous key when fallback logic applies. |
| `seriesGroupingConfidence` | string | Required | Enum `"high" | "medium" | "low"`. |
| `yearFrom` | number \| null | Optional | Deterministic span when derivable without LLM. |
| `yearTo` | number \| null | Optional | Deterministic span when derivable without LLM. |
| `yearConfidence` | string | Optional | Enum defined above; reflects programmatic certainty. |

#### `data/series-raw.json`
- Deterministic grouping step represented as an object keyed by `seriesId`.
- Fields per entry:

| Field | Type | Required | Notes |
| --- | --- | --- | --- |
| `seriesId` | string | Required | Stable identifier copied from programmatic episodes. |
| `seriesKey` | string | Optional | Normalised textual key derived from titles. |
| `seriesKeyRaw` | string \| null | Optional | Original ambiguous key when heuristic fallback used. |
| `episodeIds` | string[] | Required | Ordered membership of the series; minimum length 2. |
| `firstPublishedAt` | string | Required | ISO 8601 UTC earliest publication in the arc. |
| `seriesGroupingConfidence` | string | Required | Enum `"high" | "medium" | "low"`. |

#### `data/series-programmatic.json`
- Aggregates computed from raw groupings and programmatic episodes.
- Fields per entry:

| Field | Type | Required | Notes |
| --- | --- | --- | --- |
| `seriesId` | string | Required | Mirrors `data/series-raw.json.seriesId`. |
| `episodeIds` | string[] | Required | Ordered list matching the raw grouping. |
| `fingerprint` | string | Required | See §5 for the algorithm. |
| `memberEpisodeFingerprints` | string[] | Required | Ordered fingerprints from the episode layer. |
| `yearFrom` | number \| null | Required | Minimum member year or null. |
| `yearTo` | number \| null | Required | Maximum member year or null. |
| `yearConfidence` | string | Required | Enum; lowest confidence across members. |
| `seriesTitleFallback` | string | Required | Cleaned `seriesKey` used when LLM title is unavailable. |
| `derived` | object | Optional | Deterministic metadata such as `episodeCount` (number) or `subjectTags` (string[]). |

#### `data/episodes-llm.json`
- Cached LLM enrichments keyed by `${episodeId}:${fingerprint}`.
- Minimal schema (see §12) enforced per entry:

| Field | Type | Required | Notes |
| --- | --- | --- | --- |
| `episodeId` | string | Required | Episode identifier used to construct the cache key. |
| `fingerprint` | string | Required | Programmatic fingerprint associated with the response. |
| `model` | string | Required | LLM model identifier (`gpt-5-nano` primary, fallback lesser model when unavailable). |
| `promptVersion` | string | Required | Semantic version of the prompt template. |
| `createdAt` | string | Required | ISO 8601 UTC timestamp recorded at write. |
| `status` | string | Required | Enum `"ok" | "skipped" | "error"`. |
| `notes` | string \| null | Optional | Human-readable context for skipped/error states. |
| `keyPeople` | string[] | Required | Max 12, unique, hosts removed, whitespace-trimmed. |
| `keyPlaces` | string[] | Required | Max 12, unique, whitespace-trimmed. |
| `keyThemes` | string[] | Required | Between 3 and 8 entries, kebab-case, trimmed. |
| `yearFrom` | number \| null | Required | Numeric year or null. |
| `yearTo` | number \| null | Required | Numeric year or null. |
| `yearConfidence` | string | Required | Enum defined above. |

#### `data/series-llm.json`
- Cached LLM metadata keyed by `${seriesId}:${fingerprint}`.

| Field | Type | Required | Notes |
| --- | --- | --- | --- |
| `seriesId` | string | Required | Identifier shared across series layers. |
| `fingerprint` | string | Required | Mirrors the programmatic fingerprint used when requesting the LLM. |
| `model` | string | Required | LLM model identifier (`gpt-5-nano` primary with fallback lesser model). |
| `promptVersion` | string | Required | Semantic version string. |
| `createdAt` | string | Required | ISO 8601 UTC timestamp. |
| `status` | string | Required | Enum `"ok" | "skipped" | "error"`. |
| `notes` | string \| null | Optional | Context for skipped/error outputs. |
| `seriesTitle` | string \| null | Optional | LLM-provided human title. |
| `narrativeSummary` | string \| null | Optional | Markdown-friendly synopsis. |
| `tonalDescriptors` | string[] | Optional | Unique descriptors when present. |
| `yearFrom` | number \| null | Optional | Harmonised span aligned with episodes. |
| `yearTo` | number \| null | Optional | Harmonised span aligned with episodes. |
| `yearConfidence` | string | Required | Enum defined above. |

#### `public/episodes.json`
- Ordered array combining raw, programmatic, and LLM data per episode, sorted as described.

| Field | Type | Required | Notes |
| --- | --- | --- | --- |
| `id` | string | Required | Mirrors `episodeId`; maintained for consumer continuity. |
| `episodeId` | string | Required | Canonical ID for forward compatibility. |
| `title` | string | Required | Original episode title. |
| `publishedAt` | string | Required | ISO 8601 UTC. |
| `description` | string | Required | Original description. |
| `audioUrl` | string | Required | Direct media URL. |
| `rssLastSeenAt` | string | Required | Provenance timestamp. |
| `itunesEpisode` | number \| null | Optional | Nullable alias of the RSS iTunes episode number. |
| `cleanTitle` | string | Required | Programmatic field. |
| `cleanDescriptionMarkdown` | string | Required | Programmatic field. |
| `cleanDescriptionText` | string | Required | Programmatic field. |
| `descriptionBlocks` | string[] | Required | Programmatic field. |
| `credits` | object | Optional | Programmatic field. |
| `fingerprint` | string | Required | Programmatic fingerprint. |
| `cleanupVersion` | number | Required | Deterministic cleanup version used. |
| `derived` | object | Optional | Programmatic metadata. |
| `part` | number \| null | Optional | Multi-part index. |
| `seriesId` | string \| null | Optional | Present when part populated. |
| `seriesKey` | string \| null | Optional | Canonical key. |
| `seriesKeyRaw` | string \| null | Optional | Ambiguity trace. |
| `seriesGroupingConfidence` | string | Required | Enum. |
| `keyPeople` | string[] | Required | LLM enrichment. |
| `keyPlaces` | string[] | Required | LLM enrichment. |
| `keyThemes` | string[] | Required | LLM enrichment. |
| `yearFrom` | number \| null | Required | LLM-derived or programmatic fallback. |
| `yearTo` | number \| null | Required | LLM-derived or programmatic fallback. |
| `yearConfidence` | string | Required | Highest confidence among sources; prefer LLM. |

#### `public/series.json`
- Ordered array combining raw, programmatic, and LLM data per series, sorted by earliest `publishedAt` then `seriesId`.

| Field | Type | Required | Notes |
| --- | --- | --- | --- |
| `id` | string | Required | Mirrors `seriesId` for backwards compatibility. |
| `seriesId` | string | Required | Stable identifier used across layers. |
| `seriesKey` | string \| null | Optional | Canonical key. |
| `seriesKeyRaw` | string \| null | Optional | Ambiguity trace. |
| `seriesGroupingConfidence` | string | Required | Enum defined above. |
| `episodeIds` | string[] | Required | Ordered membership of the series. |
| `yearFrom` | number \| null | Required | Span start. |
| `yearTo` | number \| null | Required | Span end. |
| `yearConfidence` | string | Required | Confidence score. |
| `fingerprint` | string | Required | Programmatic fingerprint. |
| `memberEpisodeFingerprints` | string[] | Optional | Ordered fingerprints for downstream debugging. |
| `derived` | object | Optional | Deterministic metadata such as counts or subject tags. |
| `seriesTitle` | string | Required | LLM title or fallback. |
| `narrativeSummary` | string \| null | Optional | LLM narrative summary. |
| `tonalDescriptors` | string[] | Optional | LLM tone descriptors. |
| `rssLastSeenAt` | string \| null | Optional | Highest `rssLastSeenAt` among members. |

#### `data/errors.jsonl`
- Append-only JSON Lines ledger capturing recoverable issues.
- Each line is a JSON object with fields:

| Field | Type | Required | Notes |
| --- | --- | --- | --- |
| `stage` | string | Required | Pipeline stage emitting the error (e.g., `llm:episodes`). |
| `itemId` | string | Required | `episodeId` or `seriesId`. |
| `when` | string | Required | ISO 8601 UTC timestamp. |
| `message` | string | Required | Human-readable description. |
| `details` | object \| null | Optional | Structured payload for debugging. |

### 4.3 Formal Schemas
- Authoritative JSON Schemas live alongside the repository under:
  - [`schema/episode.public.schema.json`](../schema/episode.public.schema.json)
  - [`schema/series.public.schema.json`](../schema/series.public.schema.json)
  - [`schema/cache.llm.schema.json`](../schema/cache.llm.schema.json)
- Schemas must explicitly type every field above, including enum restrictions and `number \| null` variants for year fields.
- All public JSON artefacts (`public/episodes.json`, `public/series.json`) and cache files (`data/episodes-llm.json`, `data/series-llm.json`) MUST validate against the appropriate schema via `scripts/validate.js` using AJV.
- Schema evolution must remain backwards compatible; coordinate breaking changes with consumer version bumps.

## 5. Fingerprints & Cleanup Versioning
### 5.1 Episode Fingerprint Formula
The deterministic episode fingerprint MUST incorporate the canonicalised title and Markdown-preserving synopsis:
```
fingerprint = sha256("epfp:v1\ncleanup_v=" + CLEANUP_VERSION + "\n" + cleanTitle + "\n" + cleanDescriptionMarkdown)
```

### 5.2 Series Fingerprint Formula
```
seriesFingerprint = sha256("srfp:v1\n" + seriesId + "\n" + memberEpisodeFingerprints.join("\n"))
```

### 5.3 Programmatic Episode Enrichment
Deterministic cleanup utilities (see §11.3) MUST align with the structured extraction rules below to ensure idempotent outputs regardless of RSS description changes.

#### 5.3.1 Extraction Logic
- **Credit Extraction** — Iterate through the normalised description text (post HTML parsing, pre-boilerplate removal) and search for the following key prefixes. When a prefix is encountered at the start of a line (case-sensitive match), capture the text immediately following the prefix until the next newline. Trim whitespace and append the value to the mapped JSON field (creating arrays when multiple values exist).

  | Prefix String | Target JSON Field |
  | --- | --- |
  | `Producer:` | `credits.producer` |
  | `Senior Producer:` | `credits.seniorProducer` |
  | `Exec Producer:` | `credits.execProducer` |
  | `Executive Producer:` | `credits.execProducer` (alias) |
  | `Researcher:` | `credits.researcher` |
  | `Assistant Producer:` | `credits.assistantProducer` |
  | `Editor:` | `credits.editor` |
  | `Sound Design:` | `credits.soundDesign` |

  Normalise em dashes/colon variants to a colon before matching, and collapse multiple spaces inside the captured name.

- **Boilerplate Removal** — Evaluate each element in `descriptionBlocks` after splitting on double newlines. Drop the entire block if it contains any of the substrings listed below (case-insensitive substring match). Preserve ordering of the remaining blocks.

  - `Learn more about your ad choices`
  - `podcastchoices.com/adchoices`
  - `therestishistory.com`
  - `Join The Rest Is History Club`
  - `The Rest Is History Club`
  - `@TheRestHistory`
  - `instagram.com/theresthistory`
  - `facebook.com/theresthistory`
  - `tiktok.com/@theresthistory`
  - `Get our book`
  - `Buy tickets`
  - `Sign up to our newsletter`

### 5.4 Cleanup Version Constant
`CLEANUP_VERSION` is a constant (initially `1`) defined alongside the cleanup helpers. Increment the version whenever deterministic cleanup behaviour changes; doing so invalidates caches intentionally.

### 5.5 LLM Enrichment
LLM enrichment prompts (see §11.5) must remain versioned assets so cached responses can be invalidated deterministically when prompt semantics change.

#### 5.5.1 LLM Prompt Definitions
##### 5.5.1.1 Episode Enrichment Prompt
**System Message / Persona:**

```
You are an expert historical analyst specializing in 'The Rest Is History' podcast. Your task is to extract specific structured metadata from an episode's title and synopsis. You must adhere strictly to the output format.
```

**User Prompt:**

```
Analyze the following podcast episode details:
Title: {{cleanTitle}}
Synopsis: {{cleanDescriptionText}}
From the text provided, perform the following tasks:
Identify key historical figures mentioned. Do NOT include the hosts, Tom Holland and Dominic Sandbrook. Do NOT include producer or staff names mentioned in a credits list.
Identify key geographical places or locations central to the narrative.
Infer a numeric year span (yearFrom, yearTo) for the main historical period discussed. If the episode covers multiple distinct periods or no specific historical period (e.g., mythology, ghosts), you MUST return "NA" for both yearFrom and yearTo.
Extract up to five short, key themes or topics that summarize the episode's subject matter.
Return your analysis ONLY as a single, valid JSON object with the following schema:
```json
{
  "keyPeople": ["string"],
  "keyPlaces": ["string"],
  "keyThemes": ["string"],
  "yearFrom": "number" | "NA",
  "yearTo": "number" | "NA"
}
```
Example:
Input:
Title: 612. Nelson: The Final Showdown (Part 5)
Synopsis: "After two years at sea chasing the combined fleet of France and Spain, what was Nelson’s next step? Upon returning to his beloved Emma, how was the heroic Nelson received? What was the terrifying Napoleon Bonaparte scheming for his fleet across the seas? And, would Britain finally face an imminent French invasion, and with it apocalypse - for both Britain and Nelson himself? Join Dominic and Tom as they discuss the build up to one of the most totemic naval clashes of all time - Trafalgar - and Nelson; the man behind it all."
Expected Output:
```json
{
  "keyPeople": ["Horatio Nelson", "Emma Hamilton", "Napoleon Bonaparte"],
  "keyPlaces": ["Britain", "France", "Spain", "Trafalgar"],
  "keyThemes": ["Napoleonic Wars", "Naval Warfare", "British Navy", "French Invasion Threat", "Trafalgar Campaign"],
  "yearFrom": 1803,
  "yearTo": 1805
}
```
```

##### 5.5.1.2 Series Enrichment Prompt
**System Message / Persona:**

```
You are a skilled editor tasked with creating a compelling title and summary for a multi-part podcast series based on the titles and synopses of its individual episodes.
```

**User Prompt:**

```
Analyze the following collection of podcast episodes, which belong to a single series:
JSON
{{episodeArray}}
```
*The `episodeArray` will be a JSON array of objects, where each object has `part`, `cleanTitle`, and `cleanDescriptionText`.*

Based on the provided episodes, generate a single, consolidated `seriesTitle` and a short `narrativeSummary` (2-3 sentences) for the entire series. The title should be a human-friendly, overarching name for the arc, derived from the common themes in the episode titles.

Return your analysis ONLY as a single, valid JSON object with the following schema:
```json
{
  "seriesTitle": "string",
  "narrativeSummary": "string"
}
```
```

## 6. Series Key Extraction & Grouping Rules
- Recognise part indicators with flexible patterns: `Part`, `Pt`, `Pt.`, roman numerals (`I`, `II`, `III`, …), and hyphen/colon variants. Matching is case-insensitive.
- When ambiguity remains, still assign a `seriesId` but set `seriesGroupingConfidence = "low"` and persist `seriesKeyRaw`.
- Normalise `seriesKey` by trimming whitespace, collapsing repeated separators, and downcasing when generating the slug for `seriesId`.
- `seriesId` MUST remain stable across reruns and cannot be reused for a different arc.

## 7. Programmatic Cleanup Rules
- Boilerplate markers and credit extraction regexes live in `data/rules/cleanup.yaml`. This YAML file contains:
  - `boilerplateMarkers`: arrays of strings to remove.
  - `creditPatterns`: named regex patterns for credit extraction.
  - `htmlCollapseRules`: directives for collapsing `<br>` spam and redundant tags.
- `stripHtml` must collapse `<br>` spam using the YAML-configured rules.
- Cleanup scripts load rules from YAML at runtime; no hard-coded markers remain in code.
- Maintain unit tests under `tests/cleanup/` covering a representative sample corpus to guard against regressions.

## 8. LLM Enrichment & Cache Discipline
- Episode cache schema is locked to the minimal shape described in §4.2; extra keys are forbidden.
- Validator behaviour:
  - Trim whitespace on every string, dropping entries shorter than two characters.
  - De-duplicate arrays while preserving original order.
  - Enforce array length constraints and kebab-case for `keyThemes`.
- Cache keys remain `${itemId}:${fingerprint}`.
- `data/series-llm.json` may omit `seriesTitle` when status is not `ok`; compose will fall back to programmatic defaults.

## 9. Compose, Redaction & Public Exposure
- Compose precedence is explicit: `publicEpisode = { ...rawEpisode, ...programmaticEpisode, ...llmEpisode }`.
- Series entries apply the same overlay and publish `seriesTitle = llm.seriesTitle || seriesTitleFallback`.
- Fields excluded from the public artefacts:
  - Entire `source` object except `itunesEpisode` (mirrored as a nullable top-level field) and `rssLastSeenAt` (retained for provenance).
  - Internal helper values such as intermediate `yearHints` are not surfaced.
  - LLM metadata (`model`, `promptVersion`, `status`, `notes`) remain internal.
  - `cleanupVersion`, `fingerprint`, and `seriesGroupingConfidence` **are** public for transparency.
- Public field visibility matrix:

| Field | data/episodes | data/series | Public exposure |
| --- | --- | --- | --- |
| `fingerprint` | Programmatic | Programmatic | ✅ (public) |
| `cleanupVersion` | Programmatic | — | ✅ |
| `source.*` | Raw | — | ❌ (`itunesEpisode` exposed via alias) |
| `rssLastSeenAt` | Raw | Derived | ✅ |
| `model/promptVersion/status/notes` | LLM | LLM | ❌ |
| `seriesGroupingConfidence` | Programmatic | Programmatic | ✅ |
| `yearConfidence` | Programmatic/LLM | Programmatic/LLM | ✅ |

## 10. Validation & Contract Checks
- `scripts/validate.js` MUST:
  1. Load schemas via AJV for all public and cache files.
  2. Enforce referential integrity:
     - `episodeId` and `seriesId` uniqueness across all artefacts.
     - All `series.episodeIds[]` exist in `public/episodes.json`.
     - `yearFrom <= yearTo` whenever both values are non-null.
     - When `part` is non-null, `seriesId` MUST be non-null.
  3. Validate data hygiene:
     - Arrays (`keyPeople`, `keyPlaces`, `keyThemes`, derived tags) contain no empty strings and are de-duplicated.
     - Enumerated confidence values match the declared enums.
     - Object keys follow the stable ordering helper (fail validation if unsorted serialisation is detected).

## 11. Pipeline Flow
```
[RSS Feed]
    ↓
[data/source/rss.YYYY-MM-DD.json]
    ↓
[data/episodes-raw.json]
    ↓
[data/episodes-programmatic.json]
    ↓
[data/series-raw.json]
    ↓
[data/series-programmatic.json]
    ↓
[data/episodes-llm.json]
    ↓
[data/series-llm.json]
    ↓
[public/episodes.json, public/series.json]
    ↓
[validate]
```
Each stage reads the previous layer and only appends or updates the keyed objects for newly discovered items. Non-fatal per-item errors are logged to `data/errors.jsonl`; the pipeline continues unless validation fails.

### 11.1 Fetch RSS
- Script reads from the live feed (`FEED_URL`) and falls back to `data/source/rss.sample.xml` when offline.
- Writes a daily snapshot under `data/source/rss.YYYY-MM-DD.json` with `fetchedAt`.
- Appends unseen episodes into `data/episodes-raw.json` without altering existing entries.

### 11.2 Build Series (Raw)
- Deterministic script analyses episodes to group arcs and writes `data/series-raw.json`.
- Must handle flexible part numbering, shared prefixes, and hyphen/colon variants as described in §6.

### 11.3 Programmatic Episode Enrichment
- Shared utilities (e.g., `stripHtml`, boilerplate markers) extract clean text once per episode.
- Steps:
  1. Parse HTML → keep only meaningful paragraphs; collapse `<br>` spam using YAML rules.
  2. Identify and drop boilerplate (tour promos, social links, generic "Learn more" lines) using marker lists loaded from `data/rules/cleanup.yaml`.
  3. Extract credits into structured fields (`producer`, `execProducers`, etc.) per YAML regexes.
  4. Normalise whitespace, punctuation, and HTML entities.
  5. Compute fingerprints and persist `cleanupVersion` alongside results.
  6. Detect `Part`/`Pt`/roman numeral suffixes and assign `part`, `seriesId`, and confidence consistently.

### 11.4 Programmatic Series Enrichment
- Input: `data/series-raw.json` + `data/episodes-programmatic.json`.
- For each series:
  - Collect member episode fingerprints to compute the series fingerprint (see §5).
  - Aggregate spans and confidence across members.
  - Derive additional deterministic metadata as needed.

### 11.5 LLM Enrichment
- Episode and series scripts read the programmatic layer, filter for items whose fingerprints lack cached responses, and call OpenAI once per item unless `--force-llm <ID>` is supplied to ignore caches for specific IDs.
- Episode prompts must ignore hosts and boilerplate credits, returning only the minimal schema.
- Series prompts may supply titles, summaries, and tonal descriptors; when unavailable or status is not `ok`, compose falls back to programmatic defaults.
- Use the lightweight client in `vendor/openai` and the shared helper for retries/backoff.
- Default to the `gpt-5-nano` model (no temperature parameter supported); fall back to the designated lesser model when the primary is unavailable.
- Errors during enrichment write structured entries to `data/errors.jsonl` without aborting the run.

### 11.6 Compose
- Script merges the three layers to produce `public/*.json` using the precedence rule in §9.
- Series entries apply the same overlay and publish `seriesTitle = llm.seriesTitle || seriesTitleFallback`.
- Programmatic inputs supply `seriesTitleFallback = cleaned seriesKey` (see §13).
- Produces sorted arrays and stable key ordering.

### 11.7 Validate
- Executes the full schema + contract checks described in §10.
- Fails the pipeline when validation errors occur; otherwise succeeds even if LLM stages logged errors.

## 12. Minimal Episode LLM Schema
```
{
  "keyPeople": string[] (max 12, unique, no hosts),
  "keyPlaces": string[] (max 12, unique),
  "keyThemes": string[] (3–8, kebab-case, unique),
  "yearFrom": number \| null,
  "yearTo": number \| null,
  "yearConfidence": "high" | "medium" | "low" | "unknown"
}
```
- Validator trims whitespace, de-duplicates arrays, and drops entries shorter than 2 characters before persistence.

## 13. Series Title Fallback
- Programmatic fallback `seriesTitleFallback = cleaned seriesKey` ensures compose does not block on LLM availability.
- Public compose exposes `seriesTitle = llm.seriesTitle || seriesTitleFallback` and records `seriesTitleFallback` internally for auditing.

## 14. Error Handling & Ledger
- Non-fatal errors append to `data/errors.jsonl`; the run continues so long as validation passes.
- Validation remains the gatekeeper for exit codes.
- Include log entries for LLM errors, cleanup anomalies, and compose fallbacks.

## 15. Validation-Adjacent Guarantees
- Arrays (`keyPeople`, `keyPlaces`, `keyThemes`, `episodeIds`, derived tags) must be de-duplicated.
- No empty strings or whitespace-only entries are permitted.
- File size and ordering remain predictable via the stable serialiser.

## 16. CI & Tooling
- Command-line flags:
  - `--dry` — perform a dry run without writes.
  - `--since=YYYY-MM-DD` — limit processing to episodes published on/after the date.
  - `--force-llm <ID>` — bypass caches for a specific `episodeId` or `seriesId`.
- GitHub Actions:
  - Upload build artefacts for `public/*.json` and a `diff.txt` comparing `main` vs PR outputs.
  - Fail the job when validation fails; succeed even when LLM stages log recoverable errors.
  - Surface `data/errors.jsonl` as an artefact when entries are produced.

## 17. Incremental Behaviour & Migration
- Raw files are append-only; never rewrite old items.
- Programmatic and LLM layers are dictionaries keyed by stable IDs; only new or changed fingerprints trigger updates.
- Provide `scripts/migrate-legacy-caches.mjs` to read legacy caches and emit `episodes-llm.json` / `series-llm.json` entries keyed by the new `{id}:{fingerprint}` format with `promptVersion = "legacy-import"` and `status = "ok"`.
- Migration runs once before the new pipeline executes; document its usage alongside the other scripts.

## 18. Operational Considerations
- **Environment variables**: `OPENAI_API_KEY` must be set locally and as a GitHub repo secret (`secrets.OPENAI_API_KEY`).
- **Model defaults**: configure the OpenAI client for `gpt-5-nano` with automatic fallback to the lesser model and omit temperature arguments (unsupported by the primary model).
- **Commands** (to be updated in `package.json`):
  ```json
  {
    "scripts": {
      "fetch": "node scripts/fetch-rss.js",
      "build:series": "node scripts/build-series.js",
      "enrich:episodes": "node scripts/enrich/episodes-programmatic.mjs",
      "enrich:series": "node scripts/enrich/series-programmatic.mjs",
      "llm:episodes": "node scripts/llm/episodes.mjs",
      "llm:series": "node scripts/llm/series.mjs",
      "compose": "node scripts/enrich/compose.mjs",
      "validate": "node scripts/validate.js",
      "migrate:caches": "node scripts/migrate-legacy-caches.mjs"
    }
  }
  ```
- **CI sequence**: mirror the command flow above; drop any topic-related steps.

## 19. Success Metrics
- Running the full pipeline with no new episodes should make zero OpenAI requests and leave git clean.
- New episodes should appear end-to-end (raw → public) after a single pipeline execution.
- Manual reruns should be idempotent even if LLM calls fail (compose still produces deterministic outputs from available layers).

## 20. Risks & Mitigations
| Risk | Mitigation |
| --- | --- |
| Fingerprint drift causing unnecessary LLM calls | Keep programmatic cleanup deterministic, version cleanup helpers carefully, and document fingerprint formula. |
| Boilerplate rules accidentally remove genuine content | Maintain a test corpus of sample descriptions and review diffs when rules change. |
| Series membership changes invalidating caches | Fingerprint combines ordered episode fingerprints so membership updates automatically invalidate relevant LLM entries. |
| RSS changes or removals | Track `rssLastSeenAt` and retain snapshots for auditing; provenance allows selective backfills. |

## 21. Open Questions
- Do we need additional metadata (e.g., guest bios) that could be programmatically derived from show notes? (Requires further discovery.)
- Should we expose cleaned Markdown or plain text only? (Decide based on downstream consumer preferences.)
- Are there thresholds for delaying LLM enrichment when OpenAI rate limits occur? (Potential future enhancement.)
